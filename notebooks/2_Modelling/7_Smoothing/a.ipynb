{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "You should explain **baseline models right *before* ARIMA/SARIMA** — that’s the most logical and effective placement.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Why before?\n",
    "\n",
    "### 1. **They provide a reference point**\n",
    "\n",
    "* ARIMA/SARIMA will later be evaluated against something.\n",
    "* If you teach ARIMA first, students might lack intuition about *how good is good*.\n",
    "\n",
    "### 2. **They're simpler**\n",
    "\n",
    "* Baselines require no differencing, no lag structure, no diagnostics.\n",
    "* Students can focus on *forecasting logic* before diving into *model mechanics*.\n",
    "\n",
    "### 3. **They naturally motivate ARIMA**\n",
    "\n",
    "* Once students see that naive/seasonal naive models can’t capture trend or noise properly, ARIMA becomes a motivated solution:\n",
    "\n",
    "  > “We need something that can handle non-stationarity and autocorrelation.”\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Suggested structure\n",
    "\n",
    "### 📘 **Chapter 1: Time Series Foundations**\n",
    "\n",
    "* Time series structure, visualization, decomposition\n",
    "\n",
    "### 📘 **Chapter 2: Baseline Models**\n",
    "\n",
    "* Naive, drift, seasonal naive, mean forecast\n",
    "* Evaluate with MAE/RMSE\n",
    "\n",
    "### 📘 **Chapter 3: ARIMA & SARIMA**\n",
    "\n",
    "* Motivation: overfitting vs improvement\n",
    "* Differencing, ACF/PACF, fitting and validation\n",
    "\n",
    "---\n",
    "\n",
    "### TL;DR\n",
    "\n",
    "Put **baseline models before ARIMA/SARIMA**. They are intuitive, quick wins for students, and establish a clear bar that more complex models must surpass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Great — here’s the **full teaching sequence** after your Chapter 1 (ARIMA/SARIMA/Diagnostics), structured by chapters and lessons using the **AirPassengers dataset** (or similar) as the anchor.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Chapter 2 – Classical Baseline & Smoothing Models**\n",
    "\n",
    "### **Lesson 1 – Naive and Seasonal Naive Forecasting**\n",
    "\n",
    "* Introduce them as **benchmark models**\n",
    "* Fit:\n",
    "\n",
    "  * `y_t+1 = y_t`\n",
    "  * `y_t+h = y_{t+h-s}` (with `s=12`)\n",
    "* Show how surprisingly strong they are with seasonal data\n",
    "* Compare RMSE to ARIMA/SARIMA\n",
    "\n",
    "---\n",
    "\n",
    "### **Lesson 2 – Exponential Smoothing (ETS models)**\n",
    "\n",
    "(Follow the full structure you already have)\n",
    "\n",
    "* SES → Holt → Holt-Winters (Additive vs Multiplicative)\n",
    "* Emphasize practical differences vs ARIMA\n",
    "\n",
    "---\n",
    "\n",
    "### **Lesson 3 – Compare ETS vs SARIMA vs Naive**\n",
    "\n",
    "* Use simple walk-forward validation\n",
    "* Fix horizon = 12 months\n",
    "* Show how ETS with multiplicative seasonality often matches or beats SARIMA in this dataset\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Chapter 3 – Prophet (Additive Model Framework)**\n",
    "\n",
    "### **Lesson 1 – Introduction to Prophet**\n",
    "\n",
    "* Use `ds`, `y` structure\n",
    "* Fit Prophet on AirPassengers\n",
    "* Highlight auto trend changepoints, holiday handling, built-in weekly/yearly seasonality\n",
    "\n",
    "### **Lesson 2 – Custom Seasonality & Forecast**\n",
    "\n",
    "* Add monthly/quarterly seasonality manually\n",
    "* Forecast 24 months\n",
    "* Plot components\n",
    "\n",
    "### **Lesson 3 – Compare Prophet vs SARIMA/ETS**\n",
    "\n",
    "* Use same walk-forward split\n",
    "* Compare forecast error, runtime, and interpretability\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Chapter 4 – Walk-Forward Validation and Evaluation**\n",
    "\n",
    "### **Lesson 1 – Expanding vs Sliding Window**\n",
    "\n",
    "* Explain why expanding is best for forecasting\n",
    "* Use 5 folds over 10 years\n",
    "\n",
    "### **Lesson 2 – Forecast Horizon Impact**\n",
    "\n",
    "* Forecast 3, 6, 12, 24 months\n",
    "* Show how RMSE grows with longer horizons\n",
    "\n",
    "### **Lesson 3 – Residual Analysis & Final Selection**\n",
    "\n",
    "* Analyze residuals from each model\n",
    "* Highlight stability and error patterns\n",
    "* Discuss model retraining policies\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ (Optional) Chapter 5 – Machine Learning Forecasting\n",
    "\n",
    "Only if you go into XGBoost, Random Forest, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Final Project or Capstone Idea\n",
    "\n",
    "Let students:\n",
    "\n",
    "* Select a dataset (e.g., daily temps, sales, energy)\n",
    "* Apply SARIMA, ETS, Prophet\n",
    "* Use walk-forward validation\n",
    "* Compare performance\n",
    "* Present their chosen “production model”\n",
    "\n",
    "---\n",
    "\n",
    "Let me know your course length or target level if you want to scale up/down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "✅ Yes — that’s the perfect moment.\n",
    "\n",
    "After Prophet, students will have seen:\n",
    "\n",
    "* **ARIMA/SARIMA** (statistical, autoregressive)\n",
    "* **ETS** (exponential smoothing, trend/seasonality focused)\n",
    "* **Prophet** (additive, automated with trend changepoints)\n",
    "\n",
    "So it’s the **right time** to introduce:\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 **Chapter: Forecast Validation Techniques**\n",
    "\n",
    "### 🎯 Goal:\n",
    "\n",
    "Teach students how to **evaluate models realistically** using **time-aware validation**, which will be used in all future comparisons.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Suggested Lesson Flow\n",
    "\n",
    "### **Lesson 1: Why Train/Test Split Is Different for Time Series**\n",
    "\n",
    "* No shuffling\n",
    "* Always split chronologically\n",
    "* Show one train/test split (e.g. train = 1949–1959, test = 1960)\n",
    "* Show how this differs from random 80/20 in ML\n",
    "\n",
    "---\n",
    "\n",
    "### **Lesson 2: Walk-Forward Validation (Rolling Forecast Origin)**\n",
    "\n",
    "* Explain expanding window (most common)\n",
    "* Show how models retrain on growing data\n",
    "* Simulate multi-step forecasting (e.g. forecast 12 months at each fold)\n",
    "* Visualize: fold-by-fold evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### **Lesson 3: Evaluate Models with RMSE/MAE over Time**\n",
    "\n",
    "* Use the same train/test slices for SARIMA, ETS, Prophet\n",
    "* Compare error per fold and average RMSE\n",
    "* Introduce **baseline models again** here for benchmarking\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Bonus\n",
    "\n",
    "Add a short recap at the end of the chapter:\n",
    "\n",
    "> “From now on, this is how we’ll judge any forecasting model.”\n",
    "\n",
    "---\n",
    "\n",
    "### TL;DR\n",
    "\n",
    "Yes — after Prophet, teach **train/test splits and walk-forward validation**. This gives students a robust evaluation framework before you compare all models in later chapters.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
